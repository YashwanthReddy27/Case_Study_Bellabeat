# Case_Study_Bellabeat
**About the company:**
Bellabeat is a high-tech company that manufactures health-focused products. Collecting data on activity, sleep, stress, and reproductive health has allowed Bellabeat to empower women with  knowledge about their own health and habits. Since it was founded in 2013, Bellabeat has grown rapidly and has quickly positioned  itself as a tech-driven wellness company for women. 

You can access the  RStudio project link: [Casestudy](https://posit.cloud/content/9918205)

# 1. Ask 
 ## üìä Business Task

This project analyzes Fitbit smart device usage data to uncover customer trends and behavioral patterns. These insights will support Bellabeat‚Äôs marketing team by identifying the features and habits that users value most, helping to guide product marketing strategies and future development.

---

## üë• Key Stakeholder
- **Urska Srsen** ‚Äì Bellabeat Co-founder and Chief Creative Officer  
- **Sando Mur** ‚Äì Mathematician and Bellabeat Co-founder  
- **Bellabeat Marketing Team** ‚Äì Drives marketing strategies based on insights

# 2. Prepare

### 2.1 Data At Hand

The dataset was generated by Fitbit trackers and is stored in 18 CSV files, each corresponding to different tracked activities. It contains data for 30 users collected between **March 12, 2016** and **May 12, 2016**.  
The data includes various metrics such as:
- Daily activity  
- Heart rate  
- Sleep patterns  
- Steps taken, and more  

The dataset is provided in long format.

---

### 2.2 Limitations

- The dataset is small, with data from only 30 users.  
- It is outdated (from 2016).  
- Data collection is limited to specific days in the week (Tuesday to Thursday only).

---

### 2.3 Does the Data Follow ROCCC?

**ROCCC** stands for:  
**R**eliable, **O**riginal, **C**omprehensive, **C**urrent, and **C**ited.

-  **Reliable**: The data comes from only 30 users who self-reported via Amazon Mechanical Turk.  
-  **Original**: The data was distributed by third-party vendors.  
-  **Comprehensive**: While minute-level data is available for some metrics, the timeframe and population size limit its completeness.  
-  **Current**: The dataset is nearly a decade old (2016).  
-  **Cited**: The original source (Amazon MTurk) is not verifiable or peer-reviewed.

‚û° Overall, the dataset **does not fully meet the ROCCC criteria**.

# 3. Process
I used R to conduct my analysis, as it is easy to use, considering the amount of data we have.

### 3.1 Install and Load required Packages 
```r
install.packages("tidyverse")
install.packages("janitor")
install.packages("ggpubr")
install.packages("here")
install.packages("skimr")
install.packages("ggrepel")

library(tidyverse)
library(janitor)
library(ggpubr)
library(here)
library(skimr)
library(ggrepel)
library(lubridate)
library(dplyr)
```
### 3.2 Import datasets
For my analysis, I worked on three datasets and imported them into R for my Business Task.
- dailyActivity_merged
- dailyIntenisties_merged
- hourlyCalories_merged
```r
dailyActivity_merged <- read_csv("dailyActivity_merged.csv")
hourlyCalories_merged <- read_csv("hourlyCalories_merged.csv")
dailyIntensities_merged <- read_csv("dailyIntensities_merged.csv")
```
**Display Dataset**
```r
head(hourlyCalories_merged)
str(hourlyCalories_merged)
```

### 3.3 Data Formatting and Preprocessing (Blue Color represents output respectively for corresponding code)
**i. Unique Combinations**
```r
nrow(distinct(dailyActivity_merged, Id, ActivityDate)) 
[1] 940
nrow(distinct(dailyIntensities_merged, Id, ActivityDay))
[1] 940
nrow(distinct(hourlyCalories_merged, Id, ActivityHour))
[1] 22099
```
**ii. Duplicates**
```r
> sum(duplicated(dailyActivity_merged))
[1] 0
> sum(duplicated(dailyIntensities_merged))
[1] 0
> sum(duplicated(hourlyCalories_merged))
[1] 0
```
**iii. Remove Duplicates and N/A**
```r
Dataser<-Dataset %>% distinct() %>% drop_na()  #inplace of dataset replace with one of the dataset variable where you saved your dataset while reading
```
**iv. Renaming columns**
Change the column format to lowercase to maintain consistency.
```r
> dailyActivity_merged <- rename_with(dailyActivity_merged, tolower)
> dailyIntensities_merged <- rename_with(dailyIntensities_merged, tolower)
> hourlyCalories_merged <- rename_with(hourlyCalories_merged, tolower)
```
**v. Cleaning**
Changes the format of columns to ensure consistency. Ex: Replaces spaces and special characters with underscores, removes or substitutes non-ASCII characters, ensures valid R variables.
```r
clean_names(dataset)
```
**vi. Date and Time Consistency**
Formatting the Date and time columns of all CSV files for proper consistency.
```r
data <- read_csv("dailyActivity_merged.csv")
hourlyCalories_merged <- hourlyCalories_merged %>% rename(date_time = activityhour) %>% mutate(date_time = mdy_hms(date_time))
dailyIntensities_merged <- dailyIntensities_merged %>% rename(date = activityday) %>% mutate(date, format = "%m/%d/%Y")
> view(dailyIntensities_merged)
> data <- data %>% 
+    rename(date = activitydate) %>% 
+    mutate(date = as_date(date, format = "%m/%d/%Y"))
> view(data)
```
**vii. Merging datasets**
Merging the dailyActivity_merged and dailyIntensities_merged csv files to do the analysis
```r
> dailyActivity_Intensity <- merge(data, dailyIntensities_merged, by = c("id", "date"))
```

The dataset on which the entire analysis is done
```r
 df<- dailyActivity_Intensity
```

# 4. Analyze
Analyzing the above-mentioned datasets to solve the business task at hand.
**i. Summary of the Merged dataset**
I wanted to get a sense of the merged dataset to obtain an overall summary of the dataset.
```r
> summary_stats <- df %>%
+    summarise(
+        total_steps = sum(totalsteps, na.rm = TRUE),
+        avg_steps   = mean(totalsteps, na.rm = TRUE),
+        total_distance = sum(totaldistance, na.rm = TRUE),
+        avg_distance   = mean(totaldistance, na.rm = TRUE),
+        total_calories = sum(calories, na.rm = TRUE),
+        avg_calories   = mean(calories, na.rm = TRUE)
+    )
total_steps avg_steps total_distance avg_distance total_calories avg_calories
1     7179636  7637.911        5160.32     5.489702        2165393      2303.61
```
**ii. Time Series Analysis**
I wanted to check the total steps over different dates to see how they vary 
```r
ggplot(df, aes(x= date, y=totalsteps)) + geom_line() 
> + geom_point() + labs(title ="Total Steps Over Time", x = "Date", y= "Total Steps") + theme_minmal()
```
Total steps over time vs Date: [here](Graphs/1.jpg)

Checked the total distance over different dates to see how they relate to steps
Here, the steps correlate with the distance, so it shows that the steps recorded by the system were proper
```r
ggplot(df, aes(x= date, y=totaldistance)) + geom_line() 
> + geom_point() + labs(title ="Total Distance Over Time", x = "Date", y= "Distance") + theme_minmal()
```
Total distance over time vs Date: [here](Graphs/2.jpg)

Checked the total calories burned over the date
```r
ggplot(df, aes(x= date, y=calories)) + geom_line() 
> + geom_point() + labs(title ="Calories Burned Over Time", x = "Date", y= "Distance") + theme_minmal()
```
Total Calories burned over time vs Date: [here](Graphs/3.jpg)

Finding the correlation between different metrics to analyze the users better

**iii. Correlation between steps and calories**
```r
cor_steps_cal<- cor(df$totalsteps, df$calories, use = "complete.obs")
> print(paste("Correlation bw steps and Calories:", round(cor_steps_cal,2)))
[1] "Correlation between steps and Calories: 0.59‚Äù
```
```r
ggplot(df, aes(x = totalsteps, y = calories)) +
+    geom_point() +
+    geom_smooth(method = "lm", se = FALSE) +
+    labs(title = "Correlation between Total Steps and Calories",
+         x = "Total Steps",
+         y = "Calories") +
+    theme_minimal()
```

Correlation between steps and calories: [here](Graphs/4.jpg)

Additionally, I plotted the steps versus calories over time to better understand the relationship.
Checks out that calories burned relate to the number of steps taken every day, except for some outliers and other data points that would have done other jobs rather than walking/running, as you see in the correlation graph. 
```r
geom_line(aes(y= totalsteps, color ="Steps")) +
+    geom_line(aes(y = calories, color = "Calories")) + 
+    labs(title= "Steps vs Calories over time", x= "Date", y = " Value")+
+    scale_color_manual("", values = c("Steps" = "blue", "Calories" = "red"))+
+    theme_minimal()
```
steps vs calories: [here](Graphs/5.jpg)

**iv. Weekday vs Weekend Analysis**
Analyzed the data between weekends and weekdays to see how they vary, and actually to come to a conclusion, do users work out more on weekends than weekdays?

Added two new columns, weekdays and weekends
```r
df$weekday <- weekdays(df$date) 
df$weekend <- ifelse(df$weekday %in% c("Saturday", "Sunday"), "Weekend", "Weekday")
```

```r
> weekend_summary <- df %>%
+    group_by(weekend) %>%
+    summarise(
+        avg_steps = mean(totalsteps, na.rm = TRUE),
+        avg_distance = mean(totaldistance, na.rm = TRUE),
+        avg_calories = mean(calories, na.rm = TRUE)
+    )
> print(weekend_summary)
# A tibble: 2 √ó 4
  weekend avg_steps avg_distance avg_calories
  <chr>       <dbl>        <dbl>        <dbl>
1 Weekday     7669.         5.51        2302.
2 Weekend     7551.         5.45        2310.
```
Seeing the results, the workout ratio between weekends and weekdays is almost identical.

Plotting the total steps against the data type checked out that weekend revealed a normal distribution with some outliers. However, for weekdays, the distribution was left-skewed, suggesting that they may have done other work that required walking. 
```r
ggplot(df, aes(x= weekend, y = totalsteps, fill = weekend))+
+    geom_boxplot()+
+    labs(title = "Total Steps: Weekday vs Weekend",x= "Day Type" , y ="Total Steps") + theme_minimal()
```
Total steps vs Day type: [here](Graphs/6.jpg)

**v. Average steps by Day of week**
Here, we summarize the total steps, total distance, and calories for each weekday.
```r
day_of_week_summary <- df %>%
+    group_by(weekday) %>%
+    summarise(
+        avg_steps = mean(totalsteps, na.rm = TRUE),
+        avg_distance = mean(totaldistance, na.rm = TRUE),
+        avg_calories = mean(calories, na.rm = TRUE),
+        .groups = "drop"  # Ensures ungrouped output
+    )
```
Plotting the average steps by day of week
```r
> ggplot(day_of_week_summary, aes(x = weekday, y = avg_steps)) +
+    geom_col(fill = "steelblue") +
+    labs(
+        title = "Average Steps by Day of the Week",
+        x = "Day of the Week",
+        y = "Average Steps"
+    ) +
+    theme_minimal()
```
Avg steps vs Day of weekly [here](Graphs/7.jpg)

**vi. Clustering Analysis**
Performed clustering based on different activity metrics
```r
> library(cluster)
> activity_data <-scale(df %>% select(totalsteps, totaldistance, calories, veryactiveminutes.x, fairlyactiveminutes.x, lightlyactiveminutes.x))
> set.seed(123)
> clusters <- kmeans(activity_data, centers= 2)
> df$cluster <-as.factor(clusters$cluster)
```

```r
> ggplot(df, aes(x = totalsteps, y= calories, color= cluster))+
+ geom_point()+  labs(title = "Clustering of Days Based on Activity Metrics",
+                    x = "Total Steps",
+                    y = "Calories") +
+    theme_minimal()
```

Clustering based on Diff Activity Metrics [here](Graphs/8.jpg)

Checking the outliers to see if many affect the analysis. However, there was not much that would significantly affect the analysis.
```r
> boxplot_stats <- boxplot(df$totalsteps, plot = FALSE)
> outliers <- df$totalsteps[df$totalsteps %in% boxplot_stats$out]
> print(outliers)
 [1] 36019 22244 22770 22359 22988 22026 23186 29326 23629 27745 21727 21420
```

**vii. Correlation Analysis**
I wanted to check the correlation between every metric in the dataframe to see how closely they are related.
You can see that total steps and total distance are correlated, but total steps, total distance, and calories are less correlated than total steps and total distance, as we have seen before. This confirms it.
```r
> metrics <- df %>% 
+    select(totalsteps, totaldistance, calories, veryactiveminutes.x, fairlyactiveminutes.x, lightlyactiveminutes.x, sedentaryminutes.x)

> # Compute the correlation matrix
> corr_matrix <- cor(metrics, use = "complete.obs")

> # Visualize the correlation matrix
> corrplot(corr_matrix, method = "circle")
```
Correlation Matrix: [here](Graphs/9.jpg)

**Plotting the Average Intensity Levels**
I plotted by calculating the average intensity levels, but the percentage for avg_light and avg_very was Inf, maybe even more, when I plotted for the y axis at 1000 to check the percentage.
So I calculated the summary for every metric, and we can see the Max as Infinite, which caused the issue.
```r
> summary(df$pct_very_active)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
   0.00    0.00   26.16     Inf  154.45     Inf      84 
> summary(df$pct_moderately_active)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
   0.00    0.00   56.98   45.40   79.12   97.74      85 
> summary(df$pct_lightly_active)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
  43.73  687.10 1491.55     Inf 5955.52     Inf      84 
```
Hence, filtered out only the finite values for the analysis
```r
> avg_intensity <- df %>%
+     filter(is.finite(pct_very_active), is.finite(pct_moderately_active), is.finite(pct_lightly_active)) %>%
+     summarise(
+         avg_very = mean(pct_very_active, na.rm = TRUE),
+         avg_moderate = mean(pct_moderately_active, na.rm = TRUE),
+         avg_light = mean(pct_lightly_active, na.rm = TRUE)
+     ) %>%
+     tidyr::gather(key = "intensity", value = "percentage")
```
Calculated the values again and plotted them.
```r
> df <- df %>%
+     mutate(
+         total_minutes = veryactiveminutes.x + fairlyactiveminutes.x + lightlyactiveminutes.x
+     ) %>%
+     filter(total_minutes > 0) %>%
+     mutate(
+         pct_very_active = (veryactiveminutes.x / total_minutes) * 100,
+         pct_moderately_active = (fairlyactiveminutes.x / total_minutes) * 100,
+         pct_lightly_active = (lightlyactiveminutes.x / total_minutes) * 100
+     ) %>%
+     mutate(
+         pct_very_active = ifelse(pct_very_active > 100, NA, pct_very_active),
+         pct_moderately_active = ifelse(pct_moderately_active > 100, NA, pct_moderately_active),
+         pct_lightly_active = ifelse(pct_lightly_active > 100, NA, pct_lightly_active)
+     )
```
Plotting the average intensity graph
```r
> avg_intensity <- df %>%
+     summarise(
+         avg_very = mean(pct_very_active, na.rm = TRUE),
+         avg_moderate = mean(pct_moderately_active, na.rm = TRUE),
+         avg_light = mean(pct_lightly_active, na.rm = TRUE)
+     ) %>%
+     tidyr::gather(key = "intensity", value = "percentage")

> ggplot(avg_intensity, aes(x = intensity, y = percentage, fill = intensity)) +
+     geom_bar(stat = "identity") +
+     scale_y_continuous(limits = c(0, 100)) +
+     labs(
+         title = "Average Activity Intensity Levels",
+         x = "Intensity",
+         y = "Percentage (%)"
+     ) +
+     theme_minimal()
```
Avg Intensity Levels: [here](Graphs/10.jpg)

# 5. Share
All the graphs, link to the Rstudio project and data have been shared in this repo

# 6. Act


